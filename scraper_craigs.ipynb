{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to get a call request on the site\n",
    "import requests\n",
    "#For working with data frames\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " #for storing data as a csv\n",
    "import csv\n",
    "# web scraping library \n",
    "from bs4 import BeautifulSoup\n",
    "#time management\n",
    "import time\n",
    "from random import randint\n",
    "# regular expression\n",
    "import re\n",
    "import cchardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of city names we want to get data for\n",
    "cities = ['dallas','chicago', 'newyork', 'sfbay', 'losangeles', \\\n",
    "        'houston', 'phoenix', 'philadelphia', 'sanantonio', 'washingtondc',\\\n",
    "       'boston', 'nashville', 'atlanta', 'miami', 'seattle']\n",
    "\n",
    "# all pages in a city will be stored in this list\n",
    "list_of_cities = []\n",
    "\n",
    "for city in cities:\n",
    "    #say each city has approximately 1800 pages for the \"cars for sale by owner\" category\n",
    "    #we'll track these pages with page_number variable below\n",
    "    page_number = 1\n",
    "\n",
    "    #cycling through the 1800 pages\n",
    "    while page_number <=100:\n",
    "        #city_link variable takes a different city name from cities everytime through the loop\n",
    "        city_link = \"https://\" + str(city) + \".craigslist.org/d/cars-trucks-by-owner/search/cto?s=\" + \\\n",
    "        str(page_number) + \"&hasPic=1\"\n",
    "        \n",
    "        list_of_cities.append(city_link)\n",
    "        page_number += 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of city names we want to get data for\n",
    "cities = ['dallas','chicago', 'newyork', 'sfbay', 'losangeles', \\\n",
    "        'houston', 'phoenix', 'philadelphia', 'sanantonio', 'washingtondc',\\\n",
    "       'boston', 'nashville', 'atlanta', 'miami', 'seattle']\n",
    "\n",
    "# all pages in a city will be stored in this list\n",
    "list_of_links = []\n",
    "for city_link in cities:\n",
    "    #say each city has approximately 1800 pages for the \"cars for sale by owner\" category\n",
    "    #we'll track these pages with page_number variable below\n",
    "    page_number = 1\n",
    "\n",
    "    #cycling through the 1800 pages\n",
    "    while page_number <=100:\n",
    "        #city_link variable takes a different city name from cities everytime through the loop\n",
    "        test_link = \"https://\"+ str(city) + \".craigslist.org/search/ggg?is_paid=yes&query=focus%20group&sort=date#search=1~thumb~0~0\"\n",
    "        \n",
    "        list_of_links.append(test_link)\n",
    "        page_number += 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://seattle.craigslist.org/search/ggg?is_paid=yes&query=focus%20group&sort=date#search=1~thumb~0~0',\n",
       " 'https://seattle.craigslist.org/search/ggg?is_paid=yes&query=focus%20group&sort=date#search=1~thumb~0~0',\n",
       " 'https://seattle.craigslist.org/search/ggg?is_paid=yes&query=focus%20group&sort=date#search=1~thumb~0~0',\n",
       " 'https://seattle.craigslist.org/search/ggg?is_paid=yes&query=focus%20group&sort=date#search=1~thumb~0~0',\n",
       " 'https://seattle.craigslist.org/search/ggg?is_paid=yes&query=focus%20group&sort=date#search=1~thumb~0~0']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_links[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://dallas.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1&hasPic=1',\n",
       " 'https://chicago.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1&hasPic=1',\n",
       " 'https://newyork.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1&hasPic=1',\n",
       " 'https://sfbay.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1&hasPic=1',\n",
       " 'https://losangeles.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1&hasPic=1',\n",
       " 'https://houston.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1&hasPic=1',\n",
       " 'https://phoenix.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1&hasPic=1',\n",
       " 'https://philadelphia.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1&hasPic=1',\n",
       " 'https://sanantonio.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1&hasPic=1',\n",
       " 'https://washingtondc.craigslist.org/d/cars-trucks-by-owner/search/cto?s=1&hasPic=1']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_cities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "#URLs counter\n",
    "car_urls = 1\n",
    "for each_city_page in list_of_cities:\n",
    "    links_in_each_city_page = requests.get(each_city_page)\n",
    "    #parse the html object from the page to BS object\n",
    "    soup = BeautifulSoup(links_in_each_city_page.content,'lxml')\n",
    "\n",
    "    try:\n",
    "        #get the macro-container for the car posts for that page\n",
    "        posts = soup.find_all('a',class_='result-image gallery')\n",
    "\n",
    "        #get all the html links in the page and append them to a list\n",
    "        for link in posts:\n",
    "            l = link.get('href')\n",
    "            links.append(l)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # this code just helps keep count of the looping process\n",
    "if car_urls % 5 == 0:\n",
    "    city_link = l.strip()\n",
    "    start = city_link.find(\"//\") + len(\"//\")\n",
    "    end = city_link.find(\".\")\n",
    "    city_string = city_link[start:end]\n",
    "    print('Number of pages returned ->' + str(car_urls) + '---' + city_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sleep timer to manage our server requests\n",
    "time.sleep(randint(0,1))\n",
    "car_urls += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save links to csv\n",
    "df = pd.DataFrame(links)\n",
    "df.to_csv(\"./links.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links returned --> 480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1      https://chicago.craigslist.org/nch/cto/d/golf-...\n",
       "2      https://chicago.craigslist.org/wcl/cto/d/downe...\n",
       "3      https://chicago.craigslist.org/nwc/cto/d/south...\n",
       "4      https://chicago.craigslist.org/nch/cto/d/buffa...\n",
       "5      https://chicago.craigslist.org/nch/cto/d/buffa...\n",
       "                             ...                        \n",
       "476    https://miami.craigslist.org/brw/cto/d/fort-la...\n",
       "477    https://miami.craigslist.org/pbc/cto/d/west-pa...\n",
       "478    https://miami.craigslist.org/mdc/cto/d/miami-b...\n",
       "479    https://miami.craigslist.org/brw/cto/d/hollywo...\n",
       "480    https://miami.craigslist.org/brw/cto/d/fort-la...\n",
       "Name: https, Length: 480, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read links from csv\n",
    "links = pd.read_csv('./links.csv', names=['https'])\n",
    "links = links['https'][1:]\n",
    "print(\"links returned -->\", len(links))\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 links returned --> 9\n"
     ]
    }
   ],
   "source": [
    "first10 = pd.read_csv('./links.csv', names=['https'], nrows=10)\n",
    "first10 = first10['https'][1:]\n",
    "print(\"first 10 links returned -->\", len(first10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a counter\n",
    "count = 0\n",
    "\n",
    "# store vehicle details in this list\n",
    "cars = []\n",
    "\n",
    "# loop over all links in the list \n",
    "for link in first10:\n",
    "    # make HTTP requests\n",
    "    each_page = requests.get(link)\n",
    "    # The sleep function can help avoid server overload with too many requests in a short period of time\n",
    "    time.sleep(randint(1,2))\n",
    "    # store the BS object in a variable\n",
    "    page_soup = BeautifulSoup(each_page.content, 'lxml')\n",
    "\n",
    "    # loop over each link and store address\n",
    "    car_details = []\n",
    "    try:\n",
    "        # find price attribute and store in car details\n",
    "        car_details.append(page_soup.find('span', class_=\"price\").text)\n",
    "\n",
    "        # find date and time and append to car details \n",
    "        for span in page_soup.find_all('span', recursive=True):\n",
    "            if not span.attrs.values():\n",
    "                car_details.append(span.text)\n",
    "        car_details.append(\"date time: \" + page_soup.find('time', class_=\"date timeago\")\\\n",
    "                                            .text.strip().replace(':',';'))\n",
    "\n",
    "        # find date and city name and append to car details\n",
    "        city = link.strip()\n",
    "        start = city.find(\"//\") + len(\"//\")\n",
    "        end = city.find(\".\")\n",
    "        substring = city[start:end]\n",
    "        car_details.append('city:' + substring)\n",
    "\n",
    "        # find geo coordinates and append\n",
    "        geos = page_soup.findAll(\"div\",{\"class\": \"mapbox\"})\n",
    "        lat = geos[0].contents[1].get('data-latitude')\n",
    "        car_details.append('lat:' + lat.strip())\n",
    "        long = geos[0].content[1].get('data-longitude')\n",
    "        car_details.append('long:' + long.strip())\n",
    "\n",
    "        # find post body and append\n",
    "        post_body = page_soup.find(attrs={'id' : 'postingbody'}).contents[2]\n",
    "        # remove non ascii characters from post body\n",
    "        car_details.append('post_body:' + re.sub(\"[^0-9a-zA-Z]+\", \" \", post_body))\n",
    "        # find postID and append to car details / We'll use this to assign labels to images later \n",
    "        car_details.append('pID:' + link.strip().replace('html', '').replace('.', '').split('/')[-1])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$5,800', '1993 chevrolet silverado 1500', 'condition: good', 'cylinders: 8 cylinders', 'drive: 4wd', 'fuel: gas', 'odometer: 185000', 'paint color: red', 'size: full-size', 'title status: rebuilt', 'transmission: manual', 'type: pickup', 'date time: 2022-12-22 09;57', 'city:chicago', 'lat:41.684900']\n"
     ]
    }
   ],
   "source": [
    "print(car_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # perform some basic cleanup and store in clean\n",
    "clean = []\n",
    "for string in car_details:\n",
    "    # this attribute came without a label. Assign one.\n",
    "    if string == car_details[1]:\n",
    "        clean.append('year make model: ' + string)\n",
    "    # clean up price text from $9,999 --> 9999\n",
    "    if string == car_details[0]:\n",
    "        clean.append('price: ' + string.replace(',','').replace('$', ''))\n",
    "    else :\n",
    "        clean.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some attributes come without labels. Drop these\n",
    "car_final = []\n",
    "for s in clean:\n",
    "    if ':' in s:\n",
    "        car_final.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['price: 5800', 'year make model: 1993 chevrolet silverado 1500', 'condition: good', 'cylinders: 8 cylinders', 'drive: 4wd', 'fuel: gas', 'odometer: 185000', 'paint color: red', 'size: full-size', 'title status: rebuilt', 'transmission: manual', 'type: pickup', 'date time: 2022-12-22 09;57', 'city:chicago', 'lat:41.684900']\n"
     ]
    }
   ],
   "source": [
    "# append clean attributes for each vehicle to car list\n",
    "cars.append(car_final)\n",
    "count += 1\n",
    "print(car_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a counter to keep track of the loop \n",
    "if count % 100 == 0:\n",
    "    print('loop # -> ', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'price': '5800', 'year make model': '1993 chevrolet silverado 1500', 'condition': 'good', 'cylinders': '8 cylinders', 'drive': '4wd', 'fuel': 'gas', 'odometer': '185000', 'paint color': 'red', 'size': 'full-size', 'title status': 'rebuilt', 'transmission': 'manual', 'type': 'pickup', 'date time': '2022-12-22 09;57', 'city': 'chicago', 'lat': '41.684900'}\n"
     ]
    }
   ],
   "source": [
    "# method to strip() the keys and values after splitting in order to trim white-space\n",
    "def list_to_dict(rlist):\n",
    "    return dict(map(lambda s : map(str.strip, s.split(':')), rlist))\n",
    "\n",
    "# create a dictionary for label:value for each car attribute\n",
    "car_dicts = []\n",
    "for car in cars:\n",
    "    car_dict = list_to_dict(car)\n",
    "    car_dicts.append(car_dict)\n",
    "\n",
    "for i in car_dicts:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an Empty DataFrame object\n",
    "dfs = pd.DataFrame()\n",
    "\n",
    "for item in car_dicts:\n",
    "    df = pd.DataFrame.from_dict(item, orient='index').transpose()\n",
    "    # concatenante each new df from the loop into the parent df\n",
    "    dfs = pd.concat([dfs,df], axis=0, ignore_index=True, sort=True)\n",
    "    # clean duplicate year in 'year make model'\n",
    "    dfs['year_c make model'] = dfs['year make model'].str.replace(r'\\b(\\w+)(\\s+\\1)+\\b', r'\\1', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['city', 'condition', 'cylinders', 'date time', 'drive', 'fuel', 'lat',\n",
      "       'odometer', 'paint color', 'price', 'size', 'title status',\n",
      "       'transmission', 'type', 'year make model', 'year_c make model'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>date time</th>\n",
       "      <th>drive</th>\n",
       "      <th>fuel</th>\n",
       "      <th>lat</th>\n",
       "      <th>odometer</th>\n",
       "      <th>paint color</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>title status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>type</th>\n",
       "      <th>year make model</th>\n",
       "      <th>year_c make model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chicago</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>2022-12-22 09;57</td>\n",
       "      <td>4wd</td>\n",
       "      <td>gas</td>\n",
       "      <td>41.684900</td>\n",
       "      <td>185000</td>\n",
       "      <td>red</td>\n",
       "      <td>5800</td>\n",
       "      <td>full-size</td>\n",
       "      <td>rebuilt</td>\n",
       "      <td>manual</td>\n",
       "      <td>pickup</td>\n",
       "      <td>1993 chevrolet silverado 1500</td>\n",
       "      <td>1993 chevrolet silverado 1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city condition    cylinders         date time drive fuel        lat  \\\n",
       "0  chicago      good  8 cylinders  2022-12-22 09;57   4wd  gas  41.684900   \n",
       "\n",
       "  odometer paint color price       size title status transmission    type  \\\n",
       "0   185000         red  5800  full-size      rebuilt       manual  pickup   \n",
       "\n",
       "                 year make model              year_c make model  \n",
       "0  1993 chevrolet silverado 1500  1993 chevrolet silverado 1500  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dfs.columns)\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data frame to csv\n",
    "dfs.to_csv('car_data.csv', sep='\\t', encoding='utf-8')\n",
    "dfs.to_csv('/Users/keithbaranga/Documents/GitHub/craiglist_scraper/car_data.csv', sep='\\t', encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
